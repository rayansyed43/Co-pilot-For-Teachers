{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayansyed43/Co-pilot-for-teachers/blob/main/testhg3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note -** Upload \"wstestHG.py\" into your runtime and then start the execution.\n",
        "Take the IPv4 address and drop it in the tunnel for running the Streamlit interface.\n",
        "Change the port number (if need be)"
      ],
      "metadata": {
        "id": "eoPLL4A1t6VE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOouepaonHtQ",
        "outputId": "c9c2826a-7005-4e81-c1a8-039a4252d27f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.28.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.1)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 1.5s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "Requirement already satisfied: hugchat in /usr/local/lib/python3.10/dist-packages (0.3.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from hugchat) (2.31.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from hugchat) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->hugchat) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->hugchat) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->hugchat) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->hugchat) (2023.7.22)\n",
            "fatal: destination path 'docquery' already exists and is not an empty directory.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 9 not upgraded.\n",
            "Processing /content/docquery\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (1.13.1+cu116)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (1.16.3)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (0.10.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (9.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (1.10.13)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (0.3.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (2.31.0)\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (1.7.1)\n",
            "Requirement already satisfied: transformers>=4.23 in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (4.35.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (23.11.0)\n",
            "Requirement already satisfied: build in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (1.0.3)\n",
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (6.1.0)\n",
            "Requirement already satisfied: flake8-isort in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (6.1.1)\n",
            "Requirement already satisfied: isort==5.10.1 in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (5.10.1)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (3.5.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (3.20.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (7.4.3)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (4.15.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (0.1.99)\n",
            "Requirement already satisfied: twine in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (4.0.2)\n",
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.10/dist-packages (from docquery==0.0.7) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->docquery==0.0.7) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.23->docquery==0.0.7) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.23->docquery==0.0.7) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.23->docquery==0.0.7) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.23->docquery==0.0.7) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.23->docquery==0.0.7) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.23->docquery==0.0.7) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.23->docquery==0.0.7) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.23->docquery==0.0.7) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.23->docquery==0.0.7) (4.66.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->docquery==0.0.7) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black->docquery==0.0.7) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black->docquery==0.0.7) (0.11.2)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->docquery==0.0.7) (3.11.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->docquery==0.0.7) (2.0.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build->docquery==0.0.7) (1.0.0)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr->docquery==0.0.7) (0.14.1+cu116)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr->docquery==0.0.7) (4.8.1.78)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr->docquery==0.0.7) (1.11.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr->docquery==0.0.7) (0.19.3)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr->docquery==0.0.7) (0.4.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr->docquery==0.0.7) (2.0.2)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr->docquery==0.0.7) (1.3.0.post5)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr->docquery==0.0.7) (1.11.1.1)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from flake8->docquery==0.0.7) (0.7.0)\n",
            "Requirement already satisfied: pycodestyle<2.12.0,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from flake8->docquery==0.0.7) (2.11.1)\n",
            "Requirement already satisfied: pyflakes<3.2.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from flake8->docquery==0.0.7) (3.1.0)\n",
            "Requirement already satisfied: pdfminer.six==20221105 in /usr/local/lib/python3.10/dist-packages (from pdfplumber->docquery==0.0.7) (20221105)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber->docquery==0.0.7) (4.24.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber->docquery==0.0.7) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber->docquery==0.0.7) (41.0.5)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->docquery==0.0.7) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->docquery==0.0.7) (2.5.31)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->docquery==0.0.7) (1.8.0)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->docquery==0.0.7) (20.24.6)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->docquery==0.0.7) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->docquery==0.0.7) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->docquery==0.0.7) (1.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->docquery==0.0.7) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->docquery==0.0.7) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->docquery==0.0.7) (2023.7.22)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium->docquery==0.0.7) (0.23.1)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium->docquery==0.0.7) (0.11.1)\n",
            "Requirement already satisfied: pkginfo>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from twine->docquery==0.0.7) (1.9.6)\n",
            "Requirement already satisfied: readme-renderer>=35.0 in /usr/local/lib/python3.10/dist-packages (from twine->docquery==0.0.7) (42.0)\n",
            "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from twine->docquery==0.0.7) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.10/dist-packages (from twine->docquery==0.0.7) (6.8.0)\n",
            "Requirement already satisfied: keyring>=15.1 in /usr/lib/python3/dist-packages (from twine->docquery==0.0.7) (23.5.0)\n",
            "Requirement already satisfied: rfc3986>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from twine->docquery==0.0.7) (2.0.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from twine->docquery==0.0.7) (13.7.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from webdriver-manager->docquery==0.0.7) (1.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.23->docquery==0.0.7) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=3.6->twine->docquery==0.0.7) (3.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit->docquery==0.0.7) (67.7.2)\n",
            "Requirement already satisfied: nh3>=0.2.14 in /usr/local/lib/python3.10/dist-packages (from readme-renderer>=35.0->twine->docquery==0.0.7) (0.2.14)\n",
            "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.10/dist-packages (from readme-renderer>=35.0->twine->docquery==0.0.7) (0.18.1)\n",
            "Requirement already satisfied: Pygments>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from readme-renderer>=35.0->twine->docquery==0.0.7) (2.16.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->twine->docquery==0.0.7) (3.0.0)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->docquery==0.0.7) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->docquery==0.0.7) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->docquery==0.0.7) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->docquery==0.0.7) (1.3.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium->docquery==0.0.7) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3<3,>=1.21.1->requests->docquery==0.0.7) (1.7.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->docquery==0.0.7) (0.3.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr->docquery==0.0.7) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr->docquery==0.0.7) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr->docquery==0.0.7) (2.32.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr->docquery==0.0.7) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr->docquery==0.0.7) (1.4.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->docquery==0.0.7) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->docquery==0.0.7) (0.1.2)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->docquery==0.0.7) (0.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber->docquery==0.0.7) (2.21)\n",
            "Building wheels for collected packages: docquery\n",
            "  Building wheel for docquery (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docquery: filename=docquery-0.0.7-py3-none-any.whl size=35692 sha256=c7b0b90538e6cae8040dcacd6b9a989b374342acf0f13ee043076988254a2be7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-id056_gw/wheels/cf/6e/b3/03251e24faef6f9c1a363c9da505f1419cc21ba526de186b53\n",
            "Successfully built docquery\n",
            "Installing collected packages: docquery\n",
            "  Attempting uninstall: docquery\n",
            "    Found existing installation: docquery 0.0.7\n",
            "    Uninstalling docquery-0.0.7:\n",
            "      Successfully uninstalled docquery-0.0.7\n",
            "Successfully installed docquery-0.0.7\n",
            "Collecting git+https://github.com/huggingface/diffusers\n",
            "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-3qoq__ka\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-3qoq__ka\n",
            "  Resolved https://github.com/huggingface/diffusers to commit 4e54dfe985293df9e6e86828d7a2763d076879f5\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.10/dist-packages (2.32.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.24.0.dev0) (6.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.24.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.24.0.dev0) (0.19.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.24.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.24.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.24.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.24.0.dev0) (0.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.24.0.dev0) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.13.1+cu116)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]) (0.4.9)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.24.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->diffusers==0.24.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg->imageio[ffmpeg]) (67.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.24.0.dev0) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.24.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.24.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.24.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.24.0.dev0) (2023.7.22)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit bs4 transformers\n",
        "!npm install localtunnel\n",
        "!pip install hugchat\n",
        "!pip install --quiet diffusers accelerate mediapy transformers better_profanity\n",
        "#docqyery pdf\n",
        "!git clone https://github.com/impira/docquery.git\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt-get install poppler-utils\n",
        "!cd docquery && pip install .[all]\n",
        "!pip install git+https://github.com/huggingface/diffusers transformers accelerate imageio[ffmpeg] -U\n",
        "!pip install -q torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 torchtext==0.14.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu116 -U\n",
        "!pip install nltk\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5VH3t1UqN82"
      },
      "outputs": [],
      "source": [
        "!streamlit run wstestHG.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwghxpbK635O"
      },
      "outputs": [],
      "source": [
        "# !streamlit run rural_edu_sih.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmgKy0Oaquez",
        "outputId": "35fa5cac-e832-41e1-a972-b9f841ea8387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.1s\n",
            "your url is: https://puny-games-behave.loca.lt\n"
          ]
        }
      ],
      "source": [
        " !npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqYOiIUBRwKV",
        "outputId": "f33e3ad6-0168-4857-efbc-a94b1320fe85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.0.1.tar.gz (731 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.8/731.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-7.0.1-py3-none-any.whl size=21122 sha256=25f94d1ca38fea6e337f9fe473517e4efd1ffdc3e4651d86037ca9126016f5a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/32/0e/27789b6fde02bf2b320d6f1a0fd9e1354b257c5f75eefc29bc\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.0.1\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "!ngrok authtoken 24HGqrf1jrhD6NNVh9tsopK5zJ1_4bbEXFBUbD8yAECAyrP9K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whYiEm_GaD8X",
        "outputId": "e4c0d6c0-7ab0-4cc5-dc13-bcae901c0767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * ngrok tunnel \"https://5801-35-185-184-55.ngrok-free.app\" -> open this link!\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> open this link!\".format(public_url))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6aM8is-TXCQ"
      },
      "source": [
        "## Testing ahead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1Dz0hF-wcos",
        "outputId": "8e7da4a6-467a-4da3-88e5-e0b76347709b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "document-question-answering is already registered. Overwriting pipeline for task document-question-answering...\n",
            "2023-11-15 19:47:11.257 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n"
          ]
        }
      ],
      "source": [
        "# import streamlit as st\n",
        "# # from transformers import pipeline\n",
        "# # import streamlit as st\n",
        "# from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n",
        "# from bs4 import BeautifulSoup\n",
        "# import requests\n",
        "# from hugchat import hugchat\n",
        "# from hugchat.login import Login\n",
        "# import mediapy as mp\n",
        "# from better_profanity import Profanity\n",
        "# from diffusers import EulerAncestralDiscreteScheduler as EAD\n",
        "# from diffusers import StableDiffusionPipeline as sdp\n",
        "# # video\n",
        "# import torch\n",
        "# from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
        "# from diffusers.utils import export_to_video\n",
        "# from IPython.display import HTML\n",
        "# from base64 import b64encode\n",
        "# import datetime\n",
        "# import os\n",
        "# import subprocess\n",
        "# from docquery import document, pipeline\n",
        "\n",
        "\n",
        "# # qa_model = pipeline(\"question-answering\")\n",
        "\n",
        "# def has_profanity(text):\n",
        "#     return Profanity().contains_profanity(text)\n",
        "\n",
        "\n",
        "# def filter_text(text):\n",
        "#     while has_profanity(text):\n",
        "#         text = input(\"Please provide an alternative prompt: \")\n",
        "#     return text\n",
        "\n",
        "\n",
        "# def docquery1(uploaded_file):\n",
        "#     p = pipeline('document-question-answering')\n",
        "#     st.write(os.getcwd(), uploaded_file)\n",
        "#     doc = document.load_document(uploaded_file)\n",
        "#     for q in [\"what are the Components of Cloud Computing Architecture?\", \"What is cloud reference model?\"]:\n",
        "#         st.write(q, p(question=q, **doc.context))\n",
        "#     # st.write(res)\n",
        "\n",
        "\n",
        "# def hfgptinput(style, topic):\n",
        "#     st.write(\"//logging into hugchat \")\n",
        "#     email = 'ahmedmuzammil.ai@gmail.com'\n",
        "#     passwd = 'Teamsmc12#'\n",
        "#     sign = Login(email, passwd)\n",
        "#     cookies = sign.login()\n",
        "#     st.write(\"//logged into hugchat \")\n",
        "#     # Save cookies to the local directory\n",
        "#     cookie_path_dir = \"./cookies_snapshot\"\n",
        "#     sign.saveCookiesToDir(cookie_path_dir)\n",
        "\n",
        "#     # Load cookies when you restart your program:\n",
        "#     # sign = login(email, None)\n",
        "#     # cookies = sign.loadCookiesFromDir(cookie_path_dir) # This will detect if the JSON file exists, return cookies if it does and raise an Exception if it's not.\n",
        "\n",
        "#     # Create a ChatBot\n",
        "#     chatbot = hugchat.ChatBot(cookies=cookies.get_dict())  # or cookie_path=\"usercookies/<email>.json\"\n",
        "\n",
        "#     # st.write(\"querying\")\n",
        "\n",
        "#     # non stream response\n",
        "#     prompt = style + topic\n",
        "#     # query_result = chatbot.query(prompt)\n",
        "\n",
        "#     # query_result = chatbot.query(\"tell me something about cop28\")\n",
        "#     # print(query_result) # or query_result.text or query_result[\"text\"]\n",
        "#     # st.write(query_result.text)\n",
        "\n",
        "#     # # stream response\n",
        "#     # for resp in chatbot.query(\n",
        "#     #     \"Hello\",\n",
        "#     #     stream=True\n",
        "#     # ):\n",
        "#     #     print(resp)\n",
        "#     st.write(\"//Using web search to fetch real-time data\")\n",
        "#     st.write(\"//generating hook..\")\n",
        "\n",
        "#     # Use web search *new\n",
        "#     query_result = chatbot.query(prompt, web_search=True)\n",
        "#     print(query_result)  # or query_result.text or query_result[\"text\"]\n",
        "#     for source in query_result.web_search_sources:\n",
        "#         print(source.link)\n",
        "#         print(source.title)\n",
        "#         print(source.hostname)\n",
        "\n",
        "#     # Create a new conversation\n",
        "#     id = chatbot.new_conversation()\n",
        "#     chatbot.change_conversation(id)\n",
        "\n",
        "#     # Get conversation list\n",
        "#     conversation_list = chatbot.get_conversation_list()\n",
        "\n",
        "#     # Switch model (default: meta-llama/Llama-2-70b-chat-hf. )\n",
        "#     chatbot.switch_llm(0)  # Switch to `OpenAssistant/oasst-sft-6-llama-30b-xor`\n",
        "#     chatbot.switch_llm(1)  # llama 2.0\n",
        "#     return query_result\n",
        "\n",
        "\n",
        "# def video(prompt):\n",
        "#     pipe = DiffusionPipeline.from_pretrained(\"damo-vilab/text-to-video-ms-1.7b\", torch_dtype=torch.float16,\n",
        "#                                              variant=\"fp16\")\n",
        "#     st.write(\"// image gen model begin.. model = damo-vilab/text-to-video-ms-1.7b\")\n",
        "\n",
        "#     pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "#     pipe.enable_model_cpu_offload()\n",
        "#     pipe.enable_vae_slicing()\n",
        "#     os.system('mkdir /videos')\n",
        "#     # prompt = 'cutting a cake' #@param {type:\"string\"}\n",
        "#     prompt = prompt\n",
        "#     st.write(\"// generting video for:\", prompt)\n",
        "#     # st.write(os.getcwd())\n",
        "#     negative_prompt = \"low quality\"  # @param {type:\"string\"}\n",
        "#     num_frames = 30  # @param {type:\"raw\"}\n",
        "#     video_frames = pipe(prompt, negative_prompt=negative_prompt, num_inference_steps=25, num_frames=num_frames).frames\n",
        "#     output_video_path = export_to_video(video_frames)\n",
        "\n",
        "#     new_video_path = f'/videos/{datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")}.mp4'\n",
        "#     os.system('ffmpeg -y -i {output_video_path} -c:v libx264 -c:a aac -strict -2 {new_video_path} >/dev/null 2>&1')\n",
        "\n",
        "#     # output_video_path = \"input_video.mp4\"  # Replace with your input video path\n",
        "#     # new_video_path = \"output_video.mp4\"    # Replace with your desired output video path\n",
        "\n",
        "#     # Construct the ffmpeg command as a list of arguments\n",
        "#     ffmpeg_command = [\n",
        "#         \"ffmpeg\",\n",
        "#         \"-y\",  # Overwrite output file if it exists\n",
        "#         \"-i\", output_video_path,  # Input video file\n",
        "#         \"-c:v\", \"libx264\",  # Video codec\n",
        "#         \"-c:a\", \"aac\",  # Audio codec\n",
        "#         \"-strict\", \"-2\",  # Allow non-standard AAC codec\n",
        "#         new_video_path  # Output video file\n",
        "#     ]\n",
        "\n",
        "#     # Run the ffmpeg command\n",
        "#     try:\n",
        "#         subprocess.run(ffmpeg_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
        "#         print(f\"Video conversion successful. Output saved to: {new_video_path}\")\n",
        "#     except subprocess.CalledProcessError as e:\n",
        "#         print(f\"Error converting video: {e}\")\n",
        "#     # st.write(output_video_path, '->', new_video_path)\n",
        "#     st.write(\"Video generated:\")\n",
        "#     video_file = open(new_video_path, 'rb')\n",
        "#     video_bytes = video_file.read()\n",
        "#     st.video(video_bytes)\n",
        "\n",
        "\n",
        "# def images(prompt):\n",
        "#     model = \"dreamlike-art/dreamlike-photoreal-2.0\"\n",
        "#     st.write(\"// image gen model begin.. model = \", model)\n",
        "\n",
        "#     scheduler = EAD.from_pretrained(model, subfolder=\"scheduler\")\n",
        "\n",
        "#     pipe = sdp.from_pretrained(\n",
        "#         model,\n",
        "#         scheduler=scheduler\n",
        "#     )\n",
        "#     device = \"cuda\"\n",
        "\n",
        "#     pipe = pipe.to(device)\n",
        "#     prompt = prompt\n",
        "#     st.write(\"// generting images for:\", prompt)\n",
        "#     num_images = 3\n",
        "#     filtered_input = filter_text(prompt)\n",
        "#     images = pipe(\n",
        "#         filtered_input,\n",
        "#         height=512,\n",
        "#         width=512,\n",
        "#         num_inference_steps=30,  # more no of steps,  better results\n",
        "#         guidance_scale=9,  # more no of steps,  better results\n",
        "#         num_images_per_prompt=num_images\n",
        "\n",
        "#     ).images\n",
        "#     st.image(images)\n",
        "\n",
        "\n",
        "# def question_from_pdf():\n",
        "#     st.subheader(\"Question from Document/Notes (PDF)\")\n",
        "#     uploaded_file = st.file_uploader(\"Upload your notes...\", type=[\"pdf\", \"txt\", \"docx\"])\n",
        "#     # Add your code for image question extraction here\n",
        "#     if uploaded_file is not None:\n",
        "#         # Display the image\n",
        "#         st.write(uploaded_file)\n",
        "#         # docquery1(str(uploaded_file.name))\n",
        "#         # st.image(uploaded_file, caption='Uploaded Image', use_column_width=True)\n",
        "#     else:\n",
        "#         st.write(\"Please upload an image.\")\n",
        "#     # Add your code for PDF question extraction here\n",
        "\n",
        "\n",
        "# # Page for questions from an image\n",
        "# def question_from_image():\n",
        "#     st.subheader(\"Question from Image Notes\")\n",
        "#     # st.title(\"ask answers from images:\")\n",
        "#     uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "#     # Add your code for image question extraction here\n",
        "#     if uploaded_file is not None:\n",
        "#         # Display the image\n",
        "#         st.image(uploaded_file, caption='Uploaded Image', use_column_width=True)\n",
        "#     else:\n",
        "#         st.write(\"Please upload an image.\")\n",
        "\n",
        "\n",
        "# # Page for concept explanation using hooks\n",
        "# def concept_explanation():\n",
        "#     st.subheader(\"Concept Explanation Using Hooks\")\n",
        "#     topic = st.text_input(\"Enter the topic:\")\n",
        "\n",
        "#     with st.sidebar:\n",
        "#         st.markdown(\"## Style\")\n",
        "#         style_selected = st.radio(\"\", [\"Story\", \"Question\", \"Image\", \"Video\", \"Real Event\", \"Surprising Fact\"])\n",
        "\n",
        "#         st.markdown(\"## Grade Level\")\n",
        "#         grade_level_selected = st.radio(\"\", [\"Primary\", \"Secondary\"])\n",
        "\n",
        "#         st.markdown(\"## Tone\")\n",
        "#         tone_selected = st.radio(\"\", [\"Humorous\", \"Serious\"])\n",
        "#     if style_selected == \"Story\":\n",
        "#         if st.button(\"Generate Story Hook\") and topic:\n",
        "#             append = 'generate a story hook for the topic '\n",
        "#             generated_hook_hf = hfgptinput(append, topic)\n",
        "#             # generated_hook_gpt2 = generate_hook(topic, style=style_selected, grade_level=grade_level_selected, tone=tone_selected)\n",
        "#             st.subheader(\"Generated Hook:\")\n",
        "#             st.write(generated_hook_hf.text)\n",
        "#     if style_selected == \"Surprising Fact\":\n",
        "#         if st.button(\"Generate a Hook with surprising fact\") and topic:\n",
        "#             append = 'generate a hook with surprising fact for the topic'\n",
        "#             generated_hook_hf = hfgptinput(append, topic)\n",
        "#             # generated_hook_gpt2 = generate_hook(topic, style=style_selected, grade_level=grade_level_selected, tone=tone_selected)\n",
        "#             st.subheader(\"Generated Hook:\")\n",
        "#             st.write(generated_hook_hf.text)\n",
        "#     if style_selected == \"Real Event\":\n",
        "#         if st.button(\"Generate a Hook with a real-world event\") and topic:\n",
        "#             append = 'generate a hook referring to a current real world event for the topic'\n",
        "#             generated_hook_hf = hfgptinput(append, topic)\n",
        "#             # generated_hook_gpt2 = generate_hook(topic, style=style_selected, grade_level=grade_level_selected, tone=tone_selected)\n",
        "#             st.subheader(\"Generated Hook:\")\n",
        "#             st.write(generated_hook_hf.text)\n",
        "#     if style_selected == \"Image\":\n",
        "#         if st.button(\"Generate images\") and topic:\n",
        "#             prompt = topic\n",
        "#             images(prompt)\n",
        "#     if style_selected == \"Video\":\n",
        "#         if st.button(\"Generate video\") and topic:\n",
        "#             prompt = topic\n",
        "#             video(prompt)\n",
        "#     if style_selected == \"Question\":\n",
        "#         if st.button(\"Generate Question Hook\") and topic:\n",
        "#             append = 'generate a question hook for the topic '\n",
        "#             generated_hook_hf = hfgptinput(append, topic)\n",
        "#             # generated_hook_gpt2 = generate_hook(topic, style=style_selected, grade_level=grade_level_selected, tone=tone_selected)\n",
        "#             st.subheader(\"Generated Hook:\")\n",
        "#             st.write(generated_hook_hf.text)\n",
        "\n",
        "\n",
        "# def career_guide():\n",
        "#     topic = st.text_input(\"Ask away:\")\n",
        "#     if st.button(\"Ask\") and topic:\n",
        "#         append = \"career guidance on: \"\n",
        "#         generated_hook_hf = hfgptinput(append, topic)\n",
        "#         st.write(\"generated.\")\n",
        "#         st.write(generated_hook_hf.text)\n",
        "\n",
        "\n",
        "# def study_mode():\n",
        "#     st.title(\"Preferred mode of assistance\")\n",
        "#     selected_page = st.radio(\"Select one\",\n",
        "#                              [\"Question from PDF\", \"Question from Image\", \"Concept Explanation\", \"Career Guidance\"])\n",
        "\n",
        "#     if selected_page == \"Question from PDF\":\n",
        "#         question_from_pdf()\n",
        "#     elif selected_page == \"Question from Image\":\n",
        "#         question_from_image()\n",
        "#     elif selected_page == \"Concept Explanation\":\n",
        "#         concept_explanation()\n",
        "#     elif selected_page == \"Career Guidance\":\n",
        "#         career_guide()\n",
        "\n",
        "#     # st.subheader(\"Your answer will appear here: \")\n",
        "#     # output_box = st.empty()\n",
        "#     # output_box.write(\"answer..\")\n",
        "#     if st.button(\"Speak the output out loud!\"):\n",
        "#         st.write(\"using Eleven Labs API to generate AI Voice..\")\n",
        "#     language_options = [\"Assamese\", \"Bengali\", \"English\", \"Gujarati\", \"Hindi\", \"Kannada\", \"Malayalam\",\n",
        "#                         \"Marathi\", \"Oriya\", \"Punjabi\", \"Tamil\", \"Telugu\"]\n",
        "\n",
        "#     # Create a radio button for language selection\n",
        "\n",
        "#     selected_language = st.selectbox(\"Choose a language:\", language_options)\n",
        "\n",
        "#     if st.button(\"Translate\"):\n",
        "#         st.write(f\"Your translated response in {selected_language} will appear here:\")\n",
        "\n",
        "#     # user_question = st.text_input(\"Ask your question:\")\n",
        "\n",
        "#     # In this section, you would process the user_question and provide an answer\n",
        "#     # For now, let's just display a placeholder answer\n",
        "\n",
        "#     # Check if an image has been uploaded\n",
        "\n",
        "#     # st.title(\"Answer\")\n",
        "#     # st.write(\"Answer to your question will appear here.\")\n",
        "\n",
        "#     # edhook app from here\n",
        "\n",
        "#     # Collect user inputs\n",
        "\n",
        "#     # Main section\n",
        "#     # if st.button(\"Generate Hook\") and topic:\n",
        "#     #     generated_hook_gpt2 = generate_hook(topic, style=style_selected, grade_level=grade_level_selected, tone=tone_selected)\n",
        "#     #     st.subheader(\"Generated Hugging Face Hook:\")\n",
        "#     #     st.write(generated_hook_gpt2)\n",
        "\n",
        "#     # if st.button(\"Web Scrape Example\") and topic:\n",
        "#     # scraped_text = web_scrape_example(topic)\n",
        "#     # st.write(\"Web Scraped Text:\")\n",
        "#     # st.write(scraped_text)\n",
        "\n",
        "#     # Allow the user to ask queries on the scraped data\n",
        "#     # question = st.text_input(\"Ask a question about the scraped data:\")\n",
        "#     # if question:\n",
        "#     #     answer = qa_model(question=question, context=scraped_text)\n",
        "#     #     st.write(\"Answer:\")\n",
        "#     #     st.write(answer['answer'])\n",
        "\n",
        "\n",
        "# def wellness_mode():\n",
        "#     st.title(\"I'm here to listen and help. What's on your mind?\")\n",
        "#     user_input = st.text_area(\"Type your thoughts here:\")\n",
        "\n",
        "#     # In this section, you would pass user_input to LLM or any other model for processing\n",
        "#     # For now, let's just display a placeholder response\n",
        "#     st.title(\"Response\")\n",
        "#     st.write(\"Response from LLM or other model will appear here.\")\n",
        "\n",
        "\n",
        "# # Add a sidebar to the Streamlit app\n",
        "# st.sidebar.header(\"Mode\")\n",
        "# mode = st.sidebar.radio(\"Choose a mode:\", [\"Study\", \"Wellness\"])\n",
        "\n",
        "# # Display the appropriate mode based on the user's selection\n",
        "# if mode == \"Study\":\n",
        "\n",
        "#     study_mode()\n",
        "# elif mode == \"Wellness\":\n",
        "#     wellness_mode()\n",
        "\n",
        "\n",
        "# # qa_model = pipeline(\"question-answering\")\n",
        "\n",
        "\n",
        "# def has_profanity(text):\n",
        "#     return Profanity().contains_profanity(text)\n",
        "\n",
        "\n",
        "# def filter_text(text):\n",
        "#     while has_profanity(text):\n",
        "#         text = input(\"Please provide an alternative prompt: \")\n",
        "#     return text\n",
        "\n",
        "\n",
        "# def generate_hook(prompt, model=\"gpt2\", style=\"story\", grade_level=\"primary\", tone=\"humorous\"):\n",
        "#     # Customize the prompt based on selected style, grade level, and tone\n",
        "#     prompt = f\"Create a {style.lower()} hook for {grade_level} students with a {tone.lower()} tone about {prompt}\"\n",
        "\n",
        "#     tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "#     model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "#     input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=200, truncation=True)\n",
        "#     output = model.generate(input_ids, max_length=150, temperature=0.7, num_beams=5, no_repeat_ngram_size=2)\n",
        "\n",
        "#     generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "#     return generated_text\n",
        "\n",
        "\n",
        "# def images():\n",
        "#     model = \"dreamlike-art/dreamlike-photoreal-2.0\"\n",
        "#     scheduler = EAD.from_pretrained(model, subfolder=\"scheduler\")\n",
        "\n",
        "#     pipe = sdp.from_pretrained(\n",
        "#         model,\n",
        "#         scheduler=scheduler\n",
        "#     )\n",
        "#     device = \"cuda\"\n",
        "\n",
        "#     pipe = pipe.to(device)\n",
        "#     prompt = \"baking a cake\"\n",
        "#     st.write(\"generting imgs for:\", prompt)\n",
        "#     num_images = 3\n",
        "#     filtered_input = filter_text(prompt)\n",
        "#     images = pipe(\n",
        "#         filtered_input,\n",
        "#         height=512,\n",
        "#         width=512,\n",
        "#         num_inference_steps=30,  # more no of steps,  better results\n",
        "#         guidance_scale=9,  # more no of steps,  better results\n",
        "#         num_images_per_prompt=num_images\n",
        "\n",
        "#     ).images\n",
        "#     st.image(images)\n",
        "\n",
        "\n",
        "# def video():\n",
        "#     pipe = DiffusionPipeline.from_pretrained(\"damo-vilab/text-to-video-ms-1.7b\", torch_dtype=torch.float16,\n",
        "#                                              variant=\"fp16\")\n",
        "#     pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "#     pipe.enable_model_cpu_offload()\n",
        "#     pipe.enable_vae_slicing()\n",
        "#     os.system('mkdir /videos')\n",
        "#     prompt = 'cutting a cake'  # @param {type:\"string\"}\n",
        "#     st.write(\"generting video for:\", prompt)\n",
        "#     st.write(os.getcwd())\n",
        "#     negative_prompt = \"low quality\"  # @param {type:\"string\"}\n",
        "#     num_frames = 30  # @param {type:\"raw\"}\n",
        "#     video_frames = pipe(prompt, negative_prompt=negative_prompt, num_inference_steps=25, num_frames=num_frames).frames\n",
        "#     output_video_path = export_to_video(video_frames)\n",
        "\n",
        "#     new_video_path = f'/videos/{datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")}.mp4'\n",
        "#     os.system('ffmpeg -y -i {output_video_path} -c:v libx264 -c:a aac -strict -2 {new_video_path} >/dev/null 2>&1')\n",
        "\n",
        "#     st.write(output_video_path, '->', new_video_path)\n",
        "#     video_file = open(output_video_path, 'rb')\n",
        "#     video_bytes = video_file.read()\n",
        "#     st.video(video_bytes)\n",
        "\n",
        "\n",
        "# def web_scrape_example(topic):\n",
        "#     url = f'https://en.wikipedia.org/wiki/{topic}'\n",
        "#     response = requests.get(url)\n",
        "\n",
        "#     if response.status_code == 200:\n",
        "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
        "#         # Find the main content\n",
        "#         content_div = soup.find('div', {'id': 'mw-content-text'})\n",
        "#         if content_div:\n",
        "#             paragraphs = content_div.find_all('p')  # Extracting paragraphs\n",
        "#             content = '\\n'.join([p.get_text() for p in paragraphs])\n",
        "#             return content\n",
        "#         else:\n",
        "#             return \"No content found on the Wikipedia page.\"\n",
        "#     else:\n",
        "#         return \"Failed to fetch content. Check your internet connection or try a different topic.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuMBX0ZZ8uWA"
      },
      "outputs": [],
      "source": [
        "# exec(cell_str)\n",
        "# with open('wstestHG.py', 'w') as f:\n",
        "#     f.write(cell_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyHWjg2W9MRh"
      },
      "outputs": [],
      "source": [
        "#streamlit app file\n",
        "#this is our main streamlit app download it and run it as wstestHG.py\n",
        "# cell_str = '''\n",
        "\n",
        "import streamlit as st\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "# Initialize the question-answering pipeline\n",
        "qa_model = pipeline(\"question-answering\")\n",
        "\n",
        "def generate_hook(prompt, model=\"gpt2\", style=\"story\", grade_level=\"primary\", tone=\"humorous\"):\n",
        "    # Customize the prompt based on selected style, grade level, and tone\n",
        "    prompt = f\"Create a {style.lower()} hook for {grade_level} students with a {tone.lower()} tone about {prompt}\"\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=200, truncation=True)\n",
        "    output = model.generate(input_ids, max_length=150, temperature=0.7, num_beams=5, no_repeat_ngram_size=2)\n",
        "\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "def web_scrape_example(topic):\n",
        "    url = f'https://en.wikipedia.org/wiki/{topic}'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        # Find the main content\n",
        "        content_div = soup.find('div', {'id': 'mw-content-text'})\n",
        "        if content_div:\n",
        "            paragraphs = content_div.find_all('p')  # Extracting paragraphs\n",
        "            content = '\\n'.join([p.get_text() for p in paragraphs])\n",
        "            return content\n",
        "        else:\n",
        "            return \"No content found on the Wikipedia page.\"\n",
        "    else:\n",
        "        return \"Failed to fetch content. Check your internet connection or try a different topic.\"\n",
        "\n",
        "def main():\n",
        "    st.title(\"Teacher's Hook Generator App\")\n",
        "\n",
        "    # Sidebar with three vertical sections\n",
        "    with st.sidebar:\n",
        "        st.markdown(\"## Style\")\n",
        "        style_selected = st.radio(\"\", [\"Story\", \"Question\", \"Image\", \"Video\", \"Real Event\", \"Surprising Fact\"])\n",
        "\n",
        "        st.markdown(\"## Grade Level\")\n",
        "        grade_level_selected = st.radio(\"\", [\"Primary\", \"Secondary\"])\n",
        "\n",
        "        st.markdown(\"## Tone\")\n",
        "        tone_selected = st.radio(\"\", [\"Humorous\", \"Serious\"])\n",
        "\n",
        "    # Collect user inputs\n",
        "    topic = st.text_input(\"Enter the topic:\")\n",
        "\n",
        "    # Main section\n",
        "    if st.button(\"Generate Hook\") and topic:\n",
        "        generated_hook_gpt2 = generate_hook(topic, style=style_selected, grade_level=grade_level_selected, tone=tone_selected)\n",
        "        st.subheader(\"Generated Hugging Face Hook:\")\n",
        "        st.write(generated_hook_gpt2)\n",
        "\n",
        "    if st.button(\"Web Scrape Example\") and topic:\n",
        "        scraped_text = web_scrape_example(topic)\n",
        "        st.write(\"Web Scraped Text:\")\n",
        "        st.write(scraped_text)\n",
        "\n",
        "        # Allow the user to ask queries on the scraped data\n",
        "        question = st.text_input(\"Ask a question about the scraped data:\")\n",
        "        if question:\n",
        "            answer = qa_model(question=question, context=scraped_text)\n",
        "            st.write(\"Answer:\")\n",
        "            st.write(answer['answer'])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "# '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfBHnH8n-7TY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdDVYMgqv0Cj"
      },
      "outputs": [],
      "source": [
        "# from hugchat import hugchat\n",
        "# from hugchat.login import Login\n",
        "\n",
        "# # Log in to huggingface and grant authorization to huggingchat\n",
        "# email='ahmedmuzammil.ai@gmail.com'\n",
        "# passwd='Teamsmc12#'\n",
        "# sign = Login(email, passwd)\n",
        "# cookies = sign.login()\n",
        "\n",
        "# # Save cookies to the local directory\n",
        "# cookie_path_dir = \"./cookies_snapshot\"\n",
        "# sign.saveCookiesToDir(cookie_path_dir)\n",
        "\n",
        "# # Load cookies when you restart your program:\n",
        "# # sign = login(email, None)\n",
        "# # cookies = sign.loadCookiesFromDir(cookie_path_dir) # This will detect if the JSON file exists, return cookies if it does and raise an Exception if it's not.\n",
        "\n",
        "# # Create a ChatBot\n",
        "# chatbot = hugchat.ChatBot(cookies=cookies.get_dict())  # or cookie_path=\"usercookies/<email>.json\"\n",
        "\n",
        "\n",
        "# # non stream response\n",
        "# query_result = chatbot.query(\"Hi!\")\n",
        "# print(query_result) # or query_result.text or query_result[\"text\"]\n",
        "\n",
        "# # stream response\n",
        "# for resp in chatbot.query(\n",
        "#     \"Hello\",\n",
        "#     stream=True\n",
        "# ):\n",
        "#     print(resp)\n",
        "\n",
        "# # Use web search *new\n",
        "# query_result = chatbot.query(\"what is tyndall effect\", web_search=True)\n",
        "# print(query_result) # or query_result.text or query_result[\"text\"]\n",
        "# for source in query_result.web_search_sources:\n",
        "#     print(source.link)\n",
        "#     print(source.title)\n",
        "#     print(source.hostname)\n",
        "\n",
        "# # Create a new conversation\n",
        "# id = chatbot.new_conversation()\n",
        "# chatbot.change_conversation(id)\n",
        "\n",
        "# # Get conversation list\n",
        "# conversation_list = chatbot.get_conversation_list()\n",
        "\n",
        "# # Switch model (default: meta-llama/Llama-2-70b-chat-hf. )\n",
        "# chatbot.switch_llm(0) # Switch to `OpenAssistant/oasst-sft-6-llama-30b-xor`\n",
        "# chatbot.switch_llm(1) # Switch to `meta-llama/Llama-2-70b-chat-hf`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ycbMEjewGB-"
      },
      "outputs": [],
      "source": [
        "#hugging face query model\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"shahrukhx01/bert-mini-finetune-question-detection\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKW4_lS7A1ye"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = \"dreamlike-art/dreamlike-photoreal-2.0\"\n",
        "\n",
        "from diffusers import EulerAncestralDiscreteScheduler as EAD\n",
        "\n",
        "scheduler = EAD.from_pretrained(model, subfolder=\"scheduler\")\n",
        "\n",
        "from diffusers import StableDiffusionPipeline as sdp\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "pipe = sdp.from_pretrained(\n",
        "    model,\n",
        "    scheduler=scheduler\n",
        "    )\n",
        "\n",
        "pipe = pipe.to(device)\n",
        "\n",
        "from better_profanity import Profanity\n",
        "\n",
        "def has_profanity(text):\n",
        "    return Profanity().contains_profanity(text)\n",
        "\n",
        "def filter_text(text):\n",
        "    while has_profanity(text):\n",
        "        text = input(\"Please provide an alternative prompt: \")\n",
        "    return text\n",
        "\n",
        "    prompt = input(\"Enter your prompt: \")\n",
        "filtered_input = filter_text(prompt)\n",
        "print(filtered_input)\n",
        "\n",
        "import mediapy as mp\n",
        "num_images = 3\n",
        "\n",
        "images = pipe(\n",
        "    filtered_input,\n",
        "    height = 512,\n",
        "    width = 512,\n",
        "    num_inference_steps = 30, #more no of steps,  better results\n",
        "    guidance_scale = 9, #more no of steps,  better results\n",
        "    num_images_per_prompt = num_images\n",
        "\n",
        "    ).images\n",
        "\n",
        "mp.show_images(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2E2kZNdFTyVO"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = \"dreamlike-art/dreamlike-photoreal-2.0\"\n",
        "\n",
        "from diffusers import EulerAncestralDiscreteScheduler as EAD\n",
        "\n",
        "scheduler = EAD.from_pretrained(model, subfolder=\"scheduler\")\n",
        "\n",
        "from diffusers import StableDiffusionPipeline as sdp\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "pipe = sdp.from_pretrained(\n",
        "    model,\n",
        "    scheduler=scheduler\n",
        "    )\n",
        "\n",
        "pipe = pipe.to(device)\n",
        "\n",
        "from better_profanity import Profanity\n",
        "\n",
        "def has_profanity(text):\n",
        "    return Profanity().contains_profanity(text)\n",
        "\n",
        "def filter_text(text):\n",
        "    while has_profanity(text):\n",
        "        text = input(\"Please provide an alternative prompt: \")\n",
        "    return text\n",
        "\n",
        "prompt = \"baking a cake\"\n",
        "filtered_input = filter_text(prompt)\n",
        "print(filtered_input)\n",
        "\n",
        "import mediapy as mp\n",
        "num_images = 3\n",
        "\n",
        "images = pipe(\n",
        "    filtered_input,\n",
        "    height = 512,\n",
        "    width = 512,\n",
        "    num_inference_steps = 30, #more no of steps,  better results\n",
        "    guidance_scale = 9, #more no of steps,  better results\n",
        "    num_images_per_prompt = num_images\n",
        "\n",
        "    ).images\n",
        "\n",
        "mp.show_images(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5_9UVlpnFc-"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PWxsamomkI3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# nltk.download('corpus')\n",
        "def extract_keywords(text):\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords (common words that usually don't carry much meaning)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
        "\n",
        "    # Calculate word frequency distribution\n",
        "    freq_dist = FreqDist(filtered_words)\n",
        "\n",
        "    # Get the most common words (you can adjust the number as needed)\n",
        "    most_common_words = freq_dist.most_common(5)\n",
        "\n",
        "    return most_common_words\n",
        "\n",
        "# Example usage\n",
        "text = \"This is an example sentence. You can replace it with your text.\"\n",
        "keywords = extract_keywords(text)\n",
        "print(keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zetpdLimmmGh"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "def extract_keywords(text, num_keywords=5):\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords (common words that usually don't carry much meaning)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n",
        "\n",
        "    # Calculate word frequency distribution\n",
        "    freq_dist = FreqDist(filtered_words)\n",
        "\n",
        "    # Get the most common words\n",
        "    most_common_words = freq_dist.most_common(num_keywords)\n",
        "\n",
        "    # Extract only the words without frequencies\n",
        "    keyword_list = [word for word, _ in most_common_words]\n",
        "\n",
        "    return keyword_list\n",
        "\n",
        "# Example usage\n",
        "paragraph = \"Natural Language Processing is a field of artificial intelligence that focuses on the interaction between computers and humans using natural language. It involves tasks such as text processing, language understanding, and language generation.\"\n",
        "keywords = extract_keywords(paragraph)\n",
        "print(keywords)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}